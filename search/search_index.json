{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Napari Easy Augment Batch DL","text":"<p>\ud83d\ude80 Napari-Easy-Augment-Batch-dl is a user-friendly plugin for batch augmention, model training and prediction in Napari.  </p>"},{"location":"#features","title":"\ud83d\udd25 Features","text":"<p>\u2705 Batch Processing \u2013 Label, augment, train and predict with multiple images at once. \u2705 Easy Labeling \u2013 Quickly assign labels using the intuitive Napari GUI. \u2705 Seamless Integration \u2013 Works inside Napari for an interactive experience. \u2705 Customizable \u2013  A plugin mechanism allows different deep learning frameworks to be integrated.  </p>"},{"location":"#how-it-works","title":"\ud83d\udcd6 How It Works","text":"<p>1\ufe0f\u20e3 Load and Label \u2013 Import images and apply labels. 2\ufe0f\u20e3 Configure Augmentations \u2013 Choose transformations like rotation, flipping, or color augmentation. 3\ufe0f\u20e3 Train &amp; Predict \u2013 Train models and evaluate results.  </p>"},{"location":"#get-started","title":"\ud83d\ude80 Get Started","text":"<ol> <li>Install the plugin:  </li> </ol> <p>You can install the plugin via the pip or the Napari Hub</p> <p>Please note that you will also need to install one or more deep learning frameworks for the plugin to be useful.  See the dependencies page. </p> <pre><code>pip install napari-easy-augment-batch-dl\n</code></pre>"},{"location":"about/","title":"About Napari-Easy-Augment-Batch-dl","text":"<p>Napari-Easy-Augment-Batch-dl is a user-friendly plugin for Napari designed to make labeling, batch image augmentation and model training more reproducible . It provides an intuitive graphical interface integrated with Napari, that allows users to load and label images, apply augmentations, and process large datasets efficiently without requiring programming knowledge.  (While the plugin complements programming by streamlining workflows, I always encourage users to learn programming, as it provides deeper flexibility and control over their data and models).</p>"},{"location":"about/#features","title":"\ud83d\udd0d Features","text":"<ul> <li>Takes advantage of Napari's built in labelling functionality.</li> <li>Supports various augmentation techniques such as rotation, flipping, noise addition, and brightness adjustments.</li> <li>Explicitly saves augmented patches for easier trouble shooting and more repeatable training.  </li> <li>Streamlined workflow with three simple steps: Load &amp; Label, Augmentat, and Train &amp; Predict.</li> <li>Plugin mechanism to support training and prediction with different frameworks (Cellpose, Stardist, SAM, Yolo, UNET, and more)</li> </ul>"},{"location":"about/#development-contributions","title":"\ud83d\udee0\ufe0f Development &amp; Contributions","text":"<p>Napari-Easy-Augment-Batch-dl is an open-source project, and contributions are welcome! If you have feature requests, bug reports, or would like to contribute, visit our GitHub repository.</p>"},{"location":"about/#support","title":"\ud83d\udcde Support","text":"<p>For questions, issues, or feedback, please check our FAQ or open a discussion on image.sc.</p>"},{"location":"augment/","title":"Configure Augmentations","text":"<p>You need to generate augmentations before training. </p>"},{"location":"augment/#augmentation-panel","title":"\ud83c\udf9b\ufe0f Augmentation Panel","text":""},{"location":"augment/#steps","title":"Steps:","text":"<p>1\ufe0f\u20e3 Make sure you draw at least one label box and label objects within it. See here 2\ufe0f\u20e3 Select the augmentation types (rotation, flipping, brightness/contrast, etc.) 3\ufe0f\u20e3 Choose <code>Augment current image</code> or <code>Augment all images</code> 4\ufe0f\u20e3 Verify by looking in the <code>patches</code> sub-directory of your project.</p> <p>After completing above steps you should find a <code>ground truth</code> and <code>input</code> directory has been created in your project in the <code>patches directory</code> </p> <p></p> <p>Within the <code>input</code> directory you should see a collection of patches from your images, in the <code>ground truth</code> directory there should be corresponding patches taken from the label image. </p> <p></p> <p>\ud83d\udd04 Next: Train and Predict </p>"},{"location":"dependencies/","title":"Dependencies","text":"<p>Napari-Easy-Augment-Batch-DL relies on one or more deep learning frameworks being installed in your environment.  On start-up it attempts to import the following deep learning toolkits.  At least one has to be successfully imported</p> <p>Cellpose:  For instance segmentation Stardist:  For instance segmentation Pytorch:  For semantic segmentation Mobile SAM:  An approach that uses Yolo + SAM for instance segmentation. </p> <p>Other frameworks can be added via our plugin mechanism (Documentation to come)</p> <p>Below are sets of suggested installation instructions for Linux, Mac M1, and Windows.  Not all dependencies are needed.  You need atleast one deep learning framework, but for example if you would like to work with Cellpose only you do not need Stardist or SAM. </p>"},{"location":"dependencies/#linux","title":"Linux","text":"<pre><code>    conda create -n I2K2024_dl python=3.10\n    conda activate I2K2024_dl\n    pip install numpy==1.26 # \n    pip install \"napari[all]\" # requires quotation marks to parse the square brackets on Linux, not sure if generalizes\n    pip install albumentations\n    pip install matplotlib\n    pip install \"tensorflow[and-cuda]\" # as above, requires quotation marks\n    pip install stardist \n    pip install gputools==0.2.15 # I think numpy v2.1.2 gets installed here for me\n    pip install edt # pip throws: numba v0.60.0, tensorflow v2.18.0 require lower versions of numpy. Should still work but iffy.\n    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n    pip install pytorch-lightning\n    pip install monai\n    pip install scipy\n    pip install tifffile\n    pip install cellpose\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/tnia-python.git \n    pip install git+https://github.com/True-North-Intelligent-Algorithms/segment-everything.git\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/napari-easy-augment-batch-dl.git\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything.git\n</code></pre>"},{"location":"dependencies/#mac-m1","title":"Mac M1","text":"<pre><code>    conda create -n I2K2024_dl python=3.10\n    conda activate I2K2024_dl\n    pip install numpy==1.26 # \n    pip install \"napari[all]\" # also requires quotes on Mac\n    pip install \"tensorflow[and-cuda]\" # as above, requires quotation marks. Pip throws a bunch of conflicts, but whatever.\n    pip install stardist\n    pip install gputools==0.2.15 # pip dependency incompatibilities\n    pip install edt \n    pip install torch torchvision torchaudio # remove the index flag url\n    pip install pytorch-lightning\n    pip install monai\n    pip install scipy\n    pip install tifffile\n    pip install cellpose\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/segment-everything.git\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/napari-easy-augment-batch-dl.git\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/tnia-python.git \n    pip install git+https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything.git\n</code></pre>"},{"location":"dependencies/#windows","title":"Windows","text":"<p>Note that to use GPU with Stardist in Windows we need two different environments because Windows needs an older version of tensorflow, which is not compatible wither newer version of pytorch based toolkits. </p>"},{"location":"dependencies/#windows-stardist-environment","title":"Windows stardist environment","text":"<pre><code>    conda create -n I2k2024_stardist python=3.10\n    conda activate I2k2024_stardist\n    pip install numpy==1.26\n    pip install \"napari[all]\"\n    pip install albumentations\n    pip install matplotlib\n    conda install -c conda-forge cudatoolkit=11.8 cudnn=8.1.0\n    pip install \"tensorflow&lt;2.11\"\n    pip install stardist \n    pip install gputools==0.2.15 \n    pip install edt\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/tnia-python.git \n    pip install git+https://github.com/True-North-Intelligent-Algorithms/napari-easy-augment-batch-dl.git\n</code></pre>"},{"location":"dependencies/#windows-pytorch-environment","title":"Windows pytorch environment","text":"<pre><code>    conda create -n I2k2024_pytorch python=3.10\n    conda activate I2k2024_pytorch\n    pip install numpy==1.26\n    pip install \"napari[all]\"\n    pip install albumentations\n    pip install matplotlib\n    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n    pip install pytorch-lightning\n    pip install monai\n    pip install scipy\n    pip install tifffile\n    pip install cellpose\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/segment-everything.git\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/napari-easy-augment-batch-dl.git\n    pip install git+https://github.com/True-North-Intelligent-Algorithms/tnia-python.git \n    pip install git+https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything.git\n</code></pre>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#general-questions","title":"\u2753 General Questions","text":""},{"location":"faq/#what-is-napari-easy-augment-batch-dl","title":"What is Napari-Easy-Augment-Batch-dl?","text":"<p>Napari-Easy-Augment-Batch-dl is a plugin for Napari that allows users to batch augment images easily. It provides an intuitive GUI to load images, apply augmentations, and process them efficiently.</p>"},{"location":"faq/#who-is-this-tool-for","title":"Who is this tool for?","text":"<p>This tool is designed for users who need to augment images in bulk, such as researchers, machine learning practitioners, and image analysts. No programming knowledge is required.</p>"},{"location":"faq/#usage-questions","title":"\ud83d\udd04 Usage Questions","text":""},{"location":"faq/#how-do-i-install-the-plugin","title":"How do I install the plugin?","text":"<p>You can install it using pip: <pre><code>pip install napari-easy-augment-batch-dl\n</code></pre></p>"},{"location":"load_and_label/","title":"Load and Label","text":""},{"location":"load_and_label/#preparation","title":"Preparation","text":"<p>Prior to using this plugin, put the images you want to work with in a project directory as shown below.  </p> <p></p>"},{"location":"load_and_label/#load-panel","title":"\ud83d\udccc Load Panel","text":"<p>After starting the plugin the first step is to load your images and assign labels.  </p> <p> </p> <p>1\ufe0f\u20e3 Click the Open image directory... button. 2\ufe0f\u20e3 Select the directory that contains your image files.  </p>"},{"location":"load_and_label/#drawing-labels","title":"Drawing Labels","text":"<p>1\ufe0f\u20e3 Select Label box layer and draw a label box that is as large or larger than the desired patch size. 2\ufe0f\u20e3 Select labels layer and Label objects within the label box.</p> <p></p>"},{"location":"load_and_label/#save-results","title":"Save Results","text":"<p>Select <code>Save Results</code> periodically to save the labels you have drawn.  </p> <p> </p> <p>After saving results folders should be generated for different types of deep learning artifacts.  </p> <p></p> <p>Inspect the labels directory to verify labels you have drawn have been saved.  </p>"},{"location":"load_and_label/#_1","title":"Load and Label","text":"<p>\ud83d\udd04 Next: Configure Augmentations</p>"},{"location":"overview/","title":"Overview","text":"<p>Napari-Easy-Augment-Batch-DL consists of a panel that interacts with several different Napari layers.  The below screenshot shows Napari-Easy-Augment-Batch-DL open in Napari.  </p> <p> Main screen showing various layers and annotations.</p>"},{"location":"overview/#panel-groups","title":"Panel Groups","text":"<ol> <li> <p>Load and Label: Load images then use the layers to label.</p> </li> <li> <p>Augment:  Apply augmentations to labels and save patches</p> </li> <li> <p>Train and Predict: Use patches to train models, then use model to generate predictions. </p> </li> </ol>"},{"location":"overview/#napari-easy-augment-batch-layers","title":"Napari-Easy-Augment-Batch Layers","text":"<ol> <li> <p>Images: The image set you are working with.</p> </li> <li> <p>Labels: Manually drawn labels.</p> </li> <li> <p>Predictions: Predictions from the trained model.</p> </li> <li> <p>Label Box: Indicates which regions should be used for training. Manually drawn labels outside of a label box will not be used for training. In the figure above, the blue box is a label box.</p> </li> <li> <p>ml_labels (experimental): Labels used for live ML training. Experiment with live machine learning training using these labels.</p> </li> <li> <p>Object Box: Annotate individual objects with a bounding box. This type of annotation is used for training YOLO and other object detection methods.</p> </li> <li> <p>Predicted Object Box: Predicted object box from YOLO or other object detection frameworks.</p> </li> </ol>"},{"location":"train_and_predict/","title":"Train and Predict","text":"<p>Train a model using your labeled data and make predictions on new images.  </p>"},{"location":"train_and_predict/#training-prediction-panel","title":"\ud83c\udfcb\ufe0f Training &amp; Prediction Panel","text":""},{"location":"train_and_predict/#steps","title":"Steps:","text":"<p>1\ufe0f\u20e3 Choose a model from dropdown and configure training parameters. 2\ufe0f\u20e3 Train using labeled images. 3\ufe0f\u20e3 Use the trained model to predict labels on new images.  </p>"},{"location":"train_and_predict/#training-popup","title":"Training popup","text":"<p>After hitting train a popup should appear which allows you to further adjust training parameters.  </p> <p></p> <p>After training (or after loading or setting a model) choose <code>Predict current image</code> or <code>Predict all images</code> to predict.   The <code>prediction</code> layer should be populated with the predictions as shown in the below screen shot.  </p> <p></p> <p>After predicting you need to save the project again and the predictions will be written to disk</p> <p></p> <p>The predictions will be written in your project folder under <code>predictions\\class_0</code>.  </p> <p></p> <p>\ud83d\udd04 Next: Run &amp; Export </p>"}]}